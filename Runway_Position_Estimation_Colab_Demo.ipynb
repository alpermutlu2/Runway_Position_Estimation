{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0381468b",
   "metadata": {},
   "source": [
    "# üß† AyseZeynepAhmet Depth Estimation - Colab Demo\n",
    "This Colab notebook demonstrates monocular depth estimation using the **Probabilistic DepthNet** model with SAM-based masking.\n",
    "\n",
    "You can run inference and visualize depth maps ‚Äî **no installation needed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Install dependencies (PyTorch, OpenCV, etc.)\n",
    "!pip install torch torchvision opencv-python numpy\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae28dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì§ Upload a model checkpoint and a sample RGB image\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload your .pth and image file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05760ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Visualization function\n",
    "def colorize_depth(depth_tensor, min_depth=0.1, max_depth=100.0):\n",
    "    if isinstance(depth_tensor, torch.Tensor):\n",
    "        depth_tensor = depth_tensor.squeeze().cpu().numpy()\n",
    "    depth_clipped = np.clip(depth_tensor, min_depth, max_depth)\n",
    "    depth_norm = (depth_clipped - min_depth) / (max_depth - min_depth)\n",
    "    depth_img = (depth_norm * 255).astype(np.uint8)\n",
    "    return cv2.applyColorMap(depth_img, cv2.COLORMAP_INFERNO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Load model class\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class ProbabilisticDepthNet(nn.Module):\n",
    "    def __init__(self, backbone='resnet18', min_depth=0.1, max_depth=100.0):\n",
    "        super().__init__()\n",
    "        self.min_depth = min_depth\n",
    "        self.max_depth = max_depth\n",
    "        encoder = resnet18(pretrained=True)\n",
    "        self.encoder = nn.Sequential(*list(encoder.children())[:-2])\n",
    "        self.depth_head = nn.Conv2d(512, 2, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        depth_params = self.depth_head(features)\n",
    "        mean_raw, log_var = depth_params[:, 0:1, :, :], depth_params[:, 1:2, :, :]\n",
    "        mean = torch.sigmoid(mean_raw) * (self.max_depth - self.min_depth) + self.min_depth\n",
    "        var = torch.exp(log_var)\n",
    "        mean = torch.nn.functional.interpolate(mean, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        var = torch.nn.functional.interpolate(var, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Run inference on uploaded image\n",
    "# Replace below with actual uploaded filenames if needed\n",
    "checkpoint_path = [f for f in uploaded if f.endswith('.pth')][0]\n",
    "image_path = [f for f in uploaded if f.lower().endswith(('.jpg', '.png'))][0]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ProbabilisticDepthNet().to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Load image\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((192, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "image_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    depth_pred, _ = model(image_tensor)\n",
    "\n",
    "depth_color = colorize_depth(depth_pred)\n",
    "cv2.imwrite(\"depth_colored.png\", depth_color)\n",
    "print(\"‚úÖ Depth prediction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì∏ Show result\n",
    "from IPython.display import Image as IPImage, display\n",
    "display(IPImage(\"depth_colored.png\"))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
