# Runway Position Estimator 🚁🛬

**Hybrid Visual Localization System** using MiDaS + M4Depth + RAFT + Panoptic Segmentation + LightGlue + ORB-SLAM3.

> Designed for accurate pose estimation on low-feature environments like runways.

---

## 📦 Features

✅ Modular visual pipeline (depth, flow, segmentation, pose)  
✅ Scale estimation using pitch + camera height + semantic mask  
✅ LightGlue + SuperPoint matcher  
✅ Confidence-weighted depth fusion (MiDaS, M4Depth, RAFT)  
✅ Pose refinement via PnP (optional)  
✅ Dynamic object rejection using flow-depth inconsistency  
✅ Per-frame metrics logging + Streamlit GUI  
✅ Batch KITTI sequence benchmarking  

---

## 📁 Project Structure
```
runway_position_estimator/
├── depth/                  # Depth estimation modules
│   ├── midas_inference.py
│   ├── m4depth_inference.py
│   └── raft_flow.py
├── fusion/                # Depth fusion, motion filters
│   ├── scale_recovery.py
│   ├── flow_depth_consistency.py
│   └── depth_fusion.py
├── tracking/              # Pose tracking and smoothing
│   ├── pose_fusion_manager.py
│   ├── pose_filter.py
│   └── essential_pose_estimator.py
├── segmentation/          # Semantic segmentation
│   └── panoptic_inference.py
├── frontends/
│   ├── lightglue/         # LightGlue matcher
│   └── orb_slam3/         # ORB-SLAM3 log parser
├── utils/
│   ├── trajectory_logger.py
│   └── pose_evaluator.py
├── scripts/
│   ├── integration_runner.py
│   ├── evaluate_trajectory.py
│   ├── gui_dashboard.py
│   └── run_all_kitti.py
├── models/                # Pretrained models
├── data/                  # KITTI sequences and GT
├── outputs/               # Logs, results, visualizations
├── main.py                # CLI entry point
└── requirements.txt
```

---

## 🚀 Installation

```bash
# Create virtual environment
python -m venv runway-env
source runway-env/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download model weights
# MiDaS, M4Depth, RAFT, Detectron2
# Place them in the /models/ folder
```

---

## 🔧 Usage

### ➤ Full Pipeline (per sequence)
```bash
python main.py --mode run
```

### ➤ Evaluate vs Ground Truth
```bash
python main.py --mode evaluate --gt data/poses/00.txt
```

### ➤ Visual Dashboard
```bash
streamlit run scripts/gui_dashboard.py
```

### ➤ Batch Benchmark on KITTI
```bash
python scripts/run_all_kitti.py
```

---

## 📈 Evaluation Metrics

- **ATE**: Absolute Trajectory Error
- **Scale Drift**: Relative motion deviation
- **Rotation Error**: Angular drift per frame
- **Flow Magnitude**: RAFT stability estimate
- **Num Matches**: SuperPoint + LightGlue match count

All logged to `outputs/logs/run_metrics.csv` and plotted in GUI.

---

## 📊 Benchmark Reports

Auto-generated by `run_all_kitti.py`, stored in:
```
outputs/logs/batch/
├── run_metrics_00.csv
├── run_metrics_01.csv
├── ...
```

Plots and `trajectory_cmp_*.png` help you visually assess trajectory fidelity.

---

## 💡 Notes
- All intermediate steps are saved for debug and visualization
- Easy to extend for training, ICP refinement, or lightweight SLAM
- Modular design supports component benchmarking, ablation testing

---

## 👩‍💻 Credits
Built and engineered with ❤️ by [You] and ChatGPT. Powered by open-source models and frameworks including:
- MiDaS (Intel)
- M4Depth (ETH Zurich)
- RAFT (Princeton)
- LightGlue (Magicleap)
- ORB-SLAM3 (UC3M)
- Detectron2 (Meta AI)

---

## 📬 License
MIT (or your license of choice)

---

Ready for takeoff ✈️
