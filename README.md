# Runway Position Estimator ğŸšğŸ›¬

**Hybrid Visual Localization System** using MiDaS + M4Depth + RAFT + Panoptic Segmentation + LightGlue + ORB-SLAM3.

> Designed for accurate pose estimation on low-feature environments like runways.

---

## ğŸ“¦ Features

âœ… Modular visual pipeline (depth, flow, segmentation, pose)  
âœ… Scale estimation using pitch + camera height + semantic mask  
âœ… LightGlue + SuperPoint matcher  
âœ… Confidence-weighted depth fusion (MiDaS, M4Depth, RAFT)  
âœ… Pose refinement via PnP (optional)  
âœ… Dynamic object rejection using flow-depth inconsistency  
âœ… Per-frame metrics logging + Streamlit GUI  
âœ… Batch KITTI sequence benchmarking  

---

## ğŸ“ Project Structure
```
runway_position_estimator/
â”œâ”€â”€ depth/                  # Depth estimation modules
â”‚   â”œâ”€â”€ midas_inference.py
â”‚   â”œâ”€â”€ m4depth_inference.py
â”‚   â””â”€â”€ raft_flow.py
â”œâ”€â”€ fusion/                # Depth fusion, motion filters
â”‚   â”œâ”€â”€ scale_recovery.py
â”‚   â”œâ”€â”€ flow_depth_consistency.py
â”‚   â””â”€â”€ depth_fusion.py
â”œâ”€â”€ tracking/              # Pose tracking and smoothing
â”‚   â”œâ”€â”€ pose_fusion_manager.py
â”‚   â”œâ”€â”€ pose_filter.py
â”‚   â””â”€â”€ essential_pose_estimator.py
â”œâ”€â”€ segmentation/          # Semantic segmentation
â”‚   â””â”€â”€ panoptic_inference.py
â”œâ”€â”€ frontends/
â”‚   â”œâ”€â”€ lightglue/         # LightGlue matcher
â”‚   â””â”€â”€ orb_slam3/         # ORB-SLAM3 log parser
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ trajectory_logger.py
â”‚   â””â”€â”€ pose_evaluator.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ integration_runner.py
â”‚   â”œâ”€â”€ evaluate_trajectory.py
â”‚   â”œâ”€â”€ gui_dashboard.py
â”‚   â””â”€â”€ run_all_kitti.py
â”œâ”€â”€ models/                # Pretrained models
â”œâ”€â”€ data/                  # KITTI sequences and GT
â”œâ”€â”€ outputs/               # Logs, results, visualizations
â”œâ”€â”€ main.py                # CLI entry point
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Installation

```bash
# Create virtual environment
python -m venv runway-env
source runway-env/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download model weights
# MiDaS, M4Depth, RAFT, Detectron2
# Place them in the /models/ folder
```

---

## ğŸ”§ Usage

### â¤ Full Pipeline (per sequence)
```bash
python main.py --mode run
```

### â¤ Evaluate vs Ground Truth
```bash
python main.py --mode evaluate --gt data/poses/00.txt
```

### â¤ Visual Dashboard
```bash
streamlit run scripts/gui_dashboard.py
```

### â¤ Batch Benchmark on KITTI
```bash
python scripts/run_all_kitti.py
```

---

## ğŸ“ˆ Evaluation Metrics

- **ATE**: Absolute Trajectory Error
- **Scale Drift**: Relative motion deviation
- **Rotation Error**: Angular drift per frame
- **Flow Magnitude**: RAFT stability estimate
- **Num Matches**: SuperPoint + LightGlue match count

All logged to `outputs/logs/run_metrics.csv` and plotted in GUI.

---

## ğŸ“Š Benchmark Reports

Auto-generated by `run_all_kitti.py`, stored in:
```
outputs/logs/batch/
â”œâ”€â”€ run_metrics_00.csv
â”œâ”€â”€ run_metrics_01.csv
â”œâ”€â”€ ...
```

Plots and `trajectory_cmp_*.png` help you visually assess trajectory fidelity.

---

## ğŸ’¡ Notes
- All intermediate steps are saved for debug and visualization
- Easy to extend for training, ICP refinement, or lightweight SLAM
- Modular design supports component benchmarking, ablation testing

---

## ğŸ‘©â€ğŸ’» Credits
Built and engineered with â¤ï¸ by [You] and ChatGPT. Powered by open-source models and frameworks including:
- MiDaS (Intel)
- M4Depth (ETH Zurich)
- RAFT (Princeton)
- LightGlue (Magicleap)
- ORB-SLAM3 (UC3M)
- Detectron2 (Meta AI)

---

## ğŸ“¬ License
MIT (or your license of choice)

---

Ready for takeoff âœˆï¸
